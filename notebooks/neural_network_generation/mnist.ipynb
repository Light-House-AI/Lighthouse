{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../../src/neural_network'))\n",
    "from neural_network import NeuralNetwork\n",
    "from fc_layer import FCLayer\n",
    "from activation_layer import ActivationLayer\n",
    "from activation_functions import tanh, tanh_derivative\n",
    "from loss_functions import mse, mse_derivative\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST from server\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# training data : 60000 samples\n",
    "# reshape and normalize input data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "# encode output which is a number in range [0,9] into a vector of size 10\n",
    "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "# same for test data : 10000 samples\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "net = NeuralNetwork()\n",
    "net.add(FCLayer(28*28, 100))                # input_shape=(1, 28*28)    ;   output_shape=(1, 100)\n",
    "net.add(ActivationLayer(tanh, tanh_derivative))\n",
    "net.add(FCLayer(100, 50))                   # input_shape=(1, 100)      ;   output_shape=(1, 50)\n",
    "net.add(ActivationLayer(tanh, tanh_derivative))\n",
    "net.add(FCLayer(50, 10))                    # input_shape=(1, 50)       ;   output_shape=(1, 10)\n",
    "net.add(ActivationLayer(tanh, tanh_derivative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/35   error=0.220412\n",
      "epoch 2/35   error=0.092511\n",
      "epoch 3/35   error=0.076797\n",
      "epoch 4/35   error=0.067351\n",
      "epoch 5/35   error=0.059850\n",
      "epoch 6/35   error=0.052935\n",
      "epoch 7/35   error=0.046984\n",
      "epoch 8/35   error=0.042201\n",
      "epoch 9/35   error=0.038161\n",
      "epoch 10/35   error=0.034911\n",
      "epoch 11/35   error=0.031909\n",
      "epoch 12/35   error=0.029414\n",
      "epoch 13/35   error=0.027206\n",
      "epoch 14/35   error=0.025294\n",
      "epoch 15/35   error=0.023364\n",
      "epoch 16/35   error=0.021803\n",
      "epoch 17/35   error=0.020326\n",
      "epoch 18/35   error=0.019233\n",
      "epoch 19/35   error=0.017986\n",
      "epoch 20/35   error=0.017058\n",
      "epoch 21/35   error=0.016204\n",
      "epoch 22/35   error=0.015495\n",
      "epoch 23/35   error=0.014752\n",
      "epoch 24/35   error=0.014237\n",
      "epoch 25/35   error=0.013649\n",
      "epoch 26/35   error=0.013344\n",
      "epoch 27/35   error=0.012861\n",
      "epoch 28/35   error=0.012164\n",
      "epoch 29/35   error=0.011558\n",
      "epoch 30/35   error=0.011249\n",
      "epoch 31/35   error=0.010769\n",
      "epoch 32/35   error=0.010283\n",
      "epoch 33/35   error=0.010029\n",
      "epoch 34/35   error=0.009705\n",
      "epoch 35/35   error=0.009581\n",
      "\n",
      "\n",
      "predicted values : \n",
      "[array([[-0.01822799,  0.00555004, -0.06165495,  0.11863598, -0.03412088,\n",
      "        -0.02629622, -0.00498553,  0.99159993, -0.17832492, -0.01656234]]), array([[0.03064174, 0.00801394, 0.66220317, 0.1755004 , 0.02084732,\n",
      "        0.012028  , 0.01817144, 0.01694696, 0.16495722, 0.00235791]]), array([[-0.02227991,  0.98743679,  0.22860956,  0.11993069, -0.03313987,\n",
      "        -0.02332878,  0.01106259, -0.36283831, -0.09608215,  0.01479064]])]\n",
      "true values : \n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# train on 1000 samples\n",
    "# as we didn't implemented mini-batch GD, training will be pretty slow if we update at each iteration on 60000 samples...\n",
    "net.use(mse, mse_derivative)\n",
    "net.fit(x_train[0:1000], y_train[0:1000], epochs=35, learning_rate=0.1)\n",
    "\n",
    "# test on 3 samples\n",
    "out = net.predict(x_test[0:3])\n",
    "print(\"\\n\")\n",
    "print(\"predicted values : \")\n",
    "print(out, end=\"\\n\")\n",
    "print(\"true values : \")\n",
    "print(y_test[0:3])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "009c6260f8c949f949e8d5c80e91b7d11da42068722b763148e110eb4d6efd9c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
