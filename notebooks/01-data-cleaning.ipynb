{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name, header=0, sep=','):\n",
    "    \"\"\"\n",
    "    Reads a csv file and returns a pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_name, sep=sep, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_float(value):\n",
    "    \"\"\"\n",
    "    Try to parse a string as a float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_correct_datatype(df, column):\n",
    "    float_count = df[column].apply(lambda x: try_parse_float(x)).sum() - df[column].isna().sum()\n",
    "    percentage_float = ((df.shape[0] - float_count) / df.shape[0]) * 100\n",
    "    print(column, float_count, percentage_float)\n",
    "    if percentage_float <= 25:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(val, type):\n",
    "    \"\"\"\n",
    "    Convert a value to a given type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type == 'int64':\n",
    "            return np.int64(val)\n",
    "        elif type == 'float64':\n",
    "            return np.float64(val)\n",
    "        elif type == 'uint8':\n",
    "            return np.uint8(val)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric_or_categorical(df, column):\n",
    "    unique_values = df[column].unique()\n",
    "    if ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100 < 93:\n",
    "        return True, ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100\n",
    "    return False, ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Removes columns from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows(df, rows):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop(rows, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Removes duplicates from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datatype(df, column, datatype):\n",
    "    \"\"\"\n",
    "    Converts a column to a datatype\n",
    "    \"\"\"\n",
    "    if datatype == 'object':\n",
    "        df[column] = df[column].astype(datatype)\n",
    "    else:\n",
    "        df[column] = df[column].apply(lambda x: convert_type(x, datatype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_numeric(df, column, min=-np.inf, max=np.inf):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe based on a condition\n",
    "    \"\"\"\n",
    "    if min != -np.inf and max != np.inf:\n",
    "        return df[(df[column] >= min) & (df[column] <= max)]\n",
    "    elif min == -np.inf and max != np.inf:\n",
    "        return df[(df[column] <= max)]\n",
    "    elif min != -np.inf and max == np.inf:\n",
    "        return df[(df[column] >= min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_std(df, column, std=3):\n",
    "    \"\"\"\n",
    "    Detect outliers based on standard deviation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set upper and lower limit to 3 standard deviation\n",
    "    random_data_std = np.std(df[column])\n",
    "    random_data_mean = np.mean(df[column])\n",
    "    anomaly_cut_off = random_data_std * std\n",
    "    \n",
    "    lower_limit  = random_data_mean - anomaly_cut_off \n",
    "    upper_limit = random_data_mean + anomaly_cut_off\n",
    "\n",
    "    # Generate outliers\n",
    "    outliers = (df[column] < lower_limit) | (df[column] > upper_limit)\n",
    "    df = df.loc[~outliers]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_isolation_forest(df, column, contamination=0.1):\n",
    "    \"\"\"\n",
    "    Detect outliers based on isolation forest\n",
    "    \"\"\"\n",
    "    # Create isolation forest\n",
    "    clf = IsolationForest(random_state=0, contamination=contamination)\n",
    "    predictions = clf.fit_predict(df[column].to_numpy().reshape(-1, 1))\n",
    "    return predictions == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_category_levenshtein(df, column, correct_categories, threshold=80):\n",
    "    \"\"\"\n",
    "    Corrects a column by using fuzzywuzzy to find the correct category\n",
    "    \"\"\"\n",
    "    inconsistent_categories = pd.array(list(set(df[column].unique()) - set(correct_categories)))\n",
    "    \n",
    "    for inconsistent_category in inconsistent_categories:\n",
    "        potential_match = process.extractOne(inconsistent_category, correct_categories)\n",
    "        if potential_match[1] > threshold:\n",
    "            df.loc[df[column] == inconsistent_category, column] = potential_match[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nominal_categories(df, columns):\n",
    "    \"\"\"\n",
    "    Converts categorical data to numeric data\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ordinal_category(df, column, order):\n",
    "    df[column].replace(to_replace=df[column].unique(), value=order, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, column, value):\n",
    "    \"\"\"\n",
    "    Fills missing values in a column with a value\n",
    "    \"\"\"\n",
    "    df[column].fillna(value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df, column):\n",
    "    \"\"\"\n",
    "    Drops missing values in a column\n",
    "    \"\"\"\n",
    "    df.dropna(subset=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_average_mode(df, column, is_numeric):\n",
    "    \"\"\"\n",
    "    Fills missing values in a column with the average or mode\n",
    "    \"\"\"\n",
    "    if not is_numeric:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(df, column, is_numeric):\n",
    "    \"\"\"\n",
    "    Imputation using KNN\n",
    "    \"\"\"\n",
    "    x_train = df[~df[column].isna()].copy()\n",
    "    x_train.dropna(inplace=True)\n",
    "    \n",
    "    y_train = x_train[column]\n",
    "    x_train = x_train[x_train.columns[x_train.columns != column]]\n",
    "    x_train = x_train[x_train.columns[x_train.dtypes != 'object']]\n",
    "     \n",
    "        \n",
    "    x_predict = df[df[column].isna()][df.columns[df.columns != column]].copy()\n",
    "    x_predict = x_predict[x_predict.columns[x_predict.dtypes != 'object']]\n",
    "        \n",
    "    if is_numeric:\n",
    "        # REGRESSION\n",
    "        knn_regressor = KNeighborsRegressor()\n",
    "        knn_regressor.fit(x_train, y_train)\n",
    "        y_predict = knn_regressor.predict(x_predict)\n",
    "        df.loc[df[column].isna(), column] = y_predict\n",
    "    else:\n",
    "        # CLASSIFICATION\n",
    "        knn_classifier = KNeighborsClassifier()\n",
    "        knn_classifier.fit(x_train, y_train)\n",
    "        y_predict = knn_classifier.predict(x_predict)\n",
    "        df.loc[df[column].isna(), column] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_spearman_correlation(df, column, output_column):\n",
    "    \"\"\"\n",
    "    Calculates the pearson and spearman correlation between two columns\n",
    "    \"\"\"\n",
    "    return df[column].corr(df[output_column], method='pearson'), df[column].corr(df[output_column], method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = read_data('../data/raw/titanic/titanic.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_columns(titanic_df, ['Cabin'])\n",
    "# drop_missing_values(titanic_df, 'Embarked')\n",
    "# knn_impute(titanic_df, 'Age', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(titanic_df.isna().sum())\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_data_filler(df, column, output_column, is_numeric, no_corr=0.01, low_corr=0.5):\n",
    "    if df[column].isna().sum() == 0:\n",
    "        print(column, \"No missing values\")\n",
    "        return\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    drop_missing_values(df_temp, column)\n",
    "    if df_temp[column].dtype == 'object':\n",
    "        convert_ordinal_category(df_temp, column, [x for x in range(len(df_temp[column].unique()))])\n",
    "        \n",
    "    p_score = df_temp[column].corr(df_temp[output_column], method='pearson')\n",
    "    \n",
    "    if p_score >= -no_corr and p_score <= no_corr:\n",
    "        # NO CORRELATION\n",
    "        if ((df.shape[0] - df[column].isna().sum()) / df.shape[0]) * 100 >= 50:\n",
    "            # MISSING VALUES ARE TOO LARGE\n",
    "            print(column, p_score, \"No correlation, missing values too large\")\n",
    "            remove_columns(df, [column])\n",
    "        else:\n",
    "            # MISSING VALUES ARE SMALL\n",
    "            print(column, p_score, \"No correlation, missing values small\")\n",
    "            drop_missing_values(df, column)\n",
    "    elif (p_score >= -low_corr and p_score < -no_corr) or (p_score > no_corr and p_score <= low_corr):\n",
    "        # LOW CORRELATION\n",
    "        print(column, p_score, \"Low correlation\")\n",
    "        fill_average_mode(df, column, is_numeric)\n",
    "    elif p_score >= -1 and p_score <= 1:\n",
    "        # HIGH CORRELATION\n",
    "        print(column, p_score, \"High correlation\")\n",
    "        knn_impute(df, column, is_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId No missing values\n",
      "Pclass No missing values\n",
      "Name No missing values\n",
      "Sex No missing values\n",
      "Age -0.07722109457217764 Low correlation\n",
      "SibSp No missing values\n",
      "Parch No missing values\n",
      "Ticket No missing values\n",
      "Fare No missing values\n",
      "Cabin 0.04578929038654076 Low correlation\n",
      "Embarked 0.10866867101787406 Low correlation\n"
     ]
    }
   ],
   "source": [
    "automatic_data_filler(titanic_df, 'PassengerId', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'Pclass', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Name', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Sex', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Age', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'SibSp', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'Parch', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Ticket', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Fare', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'Cabin', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Embarked', 'Survived', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris  female  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare    Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  B96 B98        S  \n",
       "1      0          PC 17599  71.2833      C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  B96 B98        S  \n",
       "3      0            113803  53.1000     C123        S  \n",
       "4      0            373450   8.0500  B96 B98        S  "
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId -0.005006660767066487\n",
      "Pclass -0.3384810359610147\n",
      "Name -0.005006660767066487\n",
      "Sex 0.5433513806577551\n",
      "Age -0.07722109457217764\n",
      "SibSp -0.017358360479534228\n",
      "Parch 0.09331700774224289\n",
      "Ticket -0.003852775513776319\n",
      "Fare 0.26818861687447865\n",
      "Cabin 0.08604457970131162\n",
      "Embarked -0.10891351318273423\n"
     ]
    }
   ],
   "source": [
    "# df_temp = titanic_df.copy()\n",
    "# for col in titanic_df.columns[titanic_df.columns != 'Survived']:\n",
    "#     drop_missing_values(df_temp, col)\n",
    "#     if df_temp[col].dtype == 'object':\n",
    "#         convert_ordinal_category(df_temp, col, [x for x in range(len(df_temp[col].unique()))])\n",
    "#     print(col, df_temp[col].corr(df_temp['Survived'], method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b5f24a5c162335a5bbbbd167f52c9e84eea168404a8cc68c92525facb849ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
