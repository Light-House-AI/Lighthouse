{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1971,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name, header=0, sep=','):\n",
    "    \"\"\"\n",
    "    Reads a csv file and returns a pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_name, sep=sep, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_float(value):\n",
    "    \"\"\"\n",
    "    Try to parse a string as a float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_correct_datatype(df, column):\n",
    "    float_count = df[column].apply(lambda x: try_parse_float(x)).sum() - df[column].isna().sum()\n",
    "    percentage_float = ((df.shape[0] - float_count) / df.shape[0]) * 100\n",
    "    if percentage_float <= 25:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(val, type):\n",
    "    \"\"\"\n",
    "    Convert a value to a given type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type == 'int64':\n",
    "            return np.int64(val)\n",
    "        elif type == 'float64':\n",
    "            return np.float64(val)\n",
    "        elif type == 'uint8':\n",
    "            return np.uint8(val)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric_or_categorical(df, column):\n",
    "    unique_values = df[column].unique()\n",
    "    if ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100 < 93:\n",
    "        return True, ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100\n",
    "    return False, ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Removes columns from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows(df, rows):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop(rows, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_condition(df, conition):\n",
    "    return df[~conition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Removes duplicates from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datatype(df, column, datatype):\n",
    "    \"\"\"\n",
    "    Converts a column to a datatype\n",
    "    \"\"\"\n",
    "    if datatype == 'object':\n",
    "        df[column] = df[column].astype(datatype)\n",
    "    else:\n",
    "        df[column] = df[column].apply(lambda x: convert_type(x, datatype))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_numeric(df, column, min=-np.inf, max=np.inf):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe based on a condition\n",
    "    \"\"\"\n",
    "    if min != -np.inf and max != np.inf:\n",
    "        return df[((df[column] >= min) & (df[column] <= max)) | df[column].isna()]\n",
    "    elif min == -np.inf and max != np.inf:\n",
    "        return df[(df[column] <= max) | df[column].isna()]\n",
    "    elif min != -np.inf and max == np.inf:\n",
    "        return df[(df[column] >= min) | df[column].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_categorical(df, column, unqiue_values):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe based on a condition\n",
    "    \"\"\"\n",
    "    inconsistent_categories = pd.array(list(set(df[column].unique()) - set(unqiue_values)))\n",
    "    return df[(~df[column].isin(inconsistent_categories)) | df[column].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_std(df, column, std=3):\n",
    "    \"\"\"\n",
    "    Detect outliers based on standard deviation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set upper and lower limit to 3 standard deviation\n",
    "    random_data_std = np.std(df[column])\n",
    "    random_data_mean = np.mean(df[column])\n",
    "    anomaly_cut_off = random_data_std * std\n",
    "    \n",
    "    lower_limit  = random_data_mean - anomaly_cut_off \n",
    "    upper_limit = random_data_mean + anomaly_cut_off\n",
    "\n",
    "    # Generate outliers\n",
    "    outliers = (df[column] < lower_limit) | (df[column] > upper_limit)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_isolation_forest(df, column, contamination=0.1):\n",
    "    \"\"\"\n",
    "    Detect outliers based on isolation forest\n",
    "    \"\"\"\n",
    "    # Create isolation forest\n",
    "    clf = IsolationForest(random_state=0, contamination=contamination)\n",
    "    predictions = clf.fit_predict(df[column].to_numpy().reshape(-1, 1))   \n",
    "    return predictions == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_category_levenshtein(df, column, incorrect_categories, threshold=80):\n",
    "    \"\"\"\n",
    "    Corrects a column by using fuzzywuzzy to find the correct category\n",
    "    \"\"\"    \n",
    "    # inconsistent_categories = pd.array(list(set(df[column].unique()) - set(incorrect_categories)))\n",
    "    inconsistent_categories = pd.array(list(incorrect_categories))\n",
    "    inconsistent_categories = inconsistent_categories[~inconsistent_categories.isna()]\n",
    "    \n",
    "    correct_categories = pd.array(list(set(df[column].unique()) - set(incorrect_categories)))\n",
    "    \n",
    "    for inconsistent_category in inconsistent_categories:\n",
    "        if not pd.isna(inconsistent_category):\n",
    "            potential_match = process.extractOne(inconsistent_category, correct_categories)\n",
    "            if potential_match[1] > threshold:\n",
    "                df.loc[df[column] == inconsistent_category, column] = potential_match[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nominal_categories(df, columns):\n",
    "    \"\"\"\n",
    "    Converts categorical data to numeric data\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ordinal_category(df, column, order):\n",
    "    df[column].replace(to_replace=df[column].unique(), value=order, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, column, value):\n",
    "    \"\"\"\n",
    "    Fills missing values in a column with a value\n",
    "    \"\"\"\n",
    "    df[column].fillna(value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df, column):\n",
    "    \"\"\"\n",
    "    Drops missing values in a column\n",
    "    \"\"\"\n",
    "    df.dropna(subset=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_average_mode(df, column, is_numeric):\n",
    "    \"\"\"\n",
    "    Fills missing values in a column with the average or mode\n",
    "    \"\"\"\n",
    "    if not is_numeric:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(df, column, is_numeric):\n",
    "    \"\"\"\n",
    "    Imputation using KNN\n",
    "    \"\"\"\n",
    "    x_train = df[~df[column].isna()].copy()\n",
    "    x_train.dropna(inplace=True)\n",
    "    \n",
    "    y_train = x_train[column]\n",
    "    x_train = x_train[x_train.columns[x_train.columns != column]]\n",
    "    x_train = x_train[x_train.columns[x_train.dtypes != 'object']]\n",
    "     \n",
    "        \n",
    "    x_predict = df[df[column].isna()][df.columns[df.columns != column]].copy()\n",
    "    x_predict = x_predict[x_predict.columns[x_predict.dtypes != 'object']]\n",
    "    \n",
    "    if x_predict.shape[0] == 0:\n",
    "        return\n",
    "    \n",
    "    if is_numeric:\n",
    "        # REGRESSION\n",
    "        knn_regressor = KNeighborsRegressor()\n",
    "        knn_regressor.fit(x_train, y_train)\n",
    "        y_predict = knn_regressor.predict(x_predict)\n",
    "        df.loc[df[column].isna(), column] = y_predict\n",
    "    else:\n",
    "        # CLASSIFICATION\n",
    "        knn_classifier = KNeighborsClassifier()\n",
    "        knn_classifier.fit(x_train, y_train)\n",
    "        y_predict = knn_classifier.predict(x_predict)\n",
    "        df.loc[df[column].isna(), column] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_data_filler(df, column, output_column, is_numeric, no_corr=0.01, low_corr=0.5):\n",
    "    if df[column].isna().sum() == 0:\n",
    "        print(column, ': No missing values')\n",
    "        return 'automatic'\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    drop_missing_values(df_temp, column)\n",
    "    if df_temp[column].dtype == 'object':\n",
    "        convert_ordinal_category(df_temp, column, [x for x in range(len(df_temp[column].unique()))])\n",
    "        \n",
    "    p_score = df_temp[column].corr(df_temp[output_column], method='pearson')\n",
    "    \n",
    "    if p_score >= -no_corr and p_score <= no_corr:\n",
    "        # NO CORRELATION\n",
    "        if ((df.shape[0] - df[column].isna().sum()) / df.shape[0]) * 100 >= 50:\n",
    "            # MISSING VALUES ARE TOO LARGE\n",
    "            # print(column, p_score, \"No correlation, missing values too large\")\n",
    "            remove_columns(df, [column])\n",
    "            return 'column'\n",
    "        else:\n",
    "            # MISSING VALUES ARE SMALL\n",
    "            # print(column, p_score, \"No correlation, missing values small\")\n",
    "            drop_missing_values(df, column)\n",
    "            return 'row'\n",
    "    elif (p_score >= -low_corr and p_score < -no_corr) or (p_score > no_corr and p_score <= low_corr):\n",
    "        # LOW CORRELATION\n",
    "        # print(column, p_score, \"Low correlation\")\n",
    "        fill_average_mode(df, column, is_numeric)\n",
    "        return 'average'\n",
    "    elif p_score >= -1 and p_score <= 1:\n",
    "        # HIGH CORRELATION\n",
    "        # print(column, p_score, \"High correlation\")\n",
    "        knn_impute(df, column, is_numeric)\n",
    "        return 'knn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_suggestions(df, output_column):\n",
    "    df_jsons = []\n",
    "    for col in df.columns[df.columns != output_column]:\n",
    "        col_json = {}\n",
    "        col_json.update({\"column_name\": col})\n",
    "        \n",
    "        # Detect Datatype\n",
    "        detect_correct_datatype(df, col)\n",
    "        if df[col].dtype == 'object':\n",
    "            col_json.update({\"datatype\": \"object\"})\n",
    "        elif df[col].dtype == 'int64':\n",
    "            col_json.update({\"datatype\": \"int64\"})\n",
    "        elif df[col].dtype == 'float64':\n",
    "            col_json.update({\"datatype\": \"float64\"})\n",
    "        elif df[col].dtype == 'uint8':\n",
    "            col_json.update({'datatype': 'uint8'})\n",
    "        \n",
    "        # Detect Numeric or Categorical\n",
    "        is_numeric = False\n",
    "        if df[col].dtype != 'object':\n",
    "            is_numeric, _ = is_numeric_or_categorical(df, col)\n",
    "        col_json.update({'is_numeric': is_numeric})\n",
    "        \n",
    "        # Detect Outliers\n",
    "        if is_numeric:\n",
    "            outliers = detect_outliers_std(df, col)\n",
    "            df = drop_rows_condition(df, outliers)\n",
    "        elif df[col].dtype != 'object':\n",
    "            outliers = detect_outliers_std(df, col)\n",
    "            df = drop_rows_condition(df, outliers)\n",
    "        elif df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.strip()\n",
    "            df_temp = df.copy()\n",
    "            convert_ordinal_category(df_temp, col, [x for x in range(len(df_temp[col].unique()))])\n",
    "            outliers = detect_outliers_isolation_forest(df_temp, col, 0.05)\n",
    "            try:\n",
    "                df = correct_category_levenshtein(df, col, df[outliers][col].unique())\n",
    "            except:\n",
    "                print(col, \"ERROR: Levenshtein\")\n",
    "                df = drop_rows_condition(df, outliers)\n",
    "                        \n",
    "        if is_numeric:\n",
    "            col_json.update({'min': df[col].min(), 'max': df[col].max(), 'mean': df[col].mean()})\n",
    "            col_json.update({'unique_count': None, 'unique_values': None})\n",
    "        elif df[col].dtype != 'object':\n",
    "            col_json.update({'min': df[col].min(), 'max': df[col].max(), 'mean': df[col].mean()})\n",
    "            col_json.update({'unique_count': len(df[col].unique()), 'unique_values': df[col].unique().tolist()})\n",
    "        elif df[col].dtype == 'object':\n",
    "            col_json.update({'min': None, 'max': None, 'mean': None})\n",
    "            col_json.update({'unique_count': len(df[col].unique()), 'unique_values': df[col].unique().tolist()})\n",
    "            \n",
    "        # Missing Data Filler\n",
    "        method = automatic_data_filler(df, col, output_column, is_numeric)\n",
    "        col_json.update({'fill_method': method})\n",
    "        \n",
    "        if method != 'column' and not is_numeric:\n",
    "            col_json.update({'unique_count': len(df[col].unique()), 'unique_values': df[col].unique().tolist()})\n",
    "        \n",
    "        # completing json\n",
    "        col_json.update({'is_nominal': True})\n",
    "        col_json.update({'ordinal_order': []})\n",
    "                \n",
    "        df_jsons.append(col_json)\n",
    "            \n",
    "    return df_jsons, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, output_column, operations):\n",
    "    for col_json in operations:\n",
    "        # Column name\n",
    "        col = col_json['column_name']\n",
    "        \n",
    "        # Check if column dropped\n",
    "        if col_json['fill_method'] == 'column':\n",
    "            remove_columns(df, [col])\n",
    "            continue\n",
    "        \n",
    "        # Convert to datatype\n",
    "        convert_to_datatype(df, col, col_json['datatype'])\n",
    "                \n",
    "        # Categorical or numeric\n",
    "        is_numeric = col_json['is_numeric']\n",
    "        print(col, df.empty, df.shape, \"OUTLIER\")\n",
    "        # Detect Outliers\n",
    "        if is_numeric:\n",
    "            df = remove_outlier_numeric(df, col, col_json['min'], col_json['max'])\n",
    "        elif df[col].dtype != 'object':\n",
    "            df = remove_outlier_categorical(df, col, col_json['unique_values'])\n",
    "        elif df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.strip()\n",
    "            outliers = pd.array(list(set(df[col].unique()) - set(col_json['unique_values'])))\n",
    "            try:\n",
    "                df = correct_category_levenshtein(df, col, outliers.to_numpy())\n",
    "            except:\n",
    "                df = drop_rows_condition(df, df[col].isin(outliers))\n",
    "        print(col, df.empty, df.shape)\n",
    "        # Fill missing data\n",
    "        if col_json['fill_method'] == 'automatic':\n",
    "            _ = automatic_data_filler(df, col, output_column, is_numeric)\n",
    "        elif col_json['fill_method'] == 'average':\n",
    "            fill_average_mode(df, col, is_numeric)\n",
    "        elif col_json['fill_method'] == 'knn':\n",
    "            knn_impute(df, col, is_numeric)\n",
    "        elif col_json['fill_method'] == 'row':\n",
    "            drop_missing_values(df, col)\n",
    "                        \n",
    "        # Convert Nominal/Ordinal\n",
    "        if df[col].dtype == 'object':\n",
    "            if col_json['is_nominal']:\n",
    "                df = convert_nominal_categories(df, [col])\n",
    "            else:\n",
    "                convert_ordinal_category(df, col, col_json['ordinal_order'])\n",
    "        print(col, df.empty, df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = read_data('../data/raw/titanic/titanic.csv', header=0)\n",
    "# remove_columns(titanic_df, ['PassengerId', 'Pclass', 'Ticket', 'Cabin', 'Age', 'Sex', 'SibSp', 'Parch', 'Fare', 'Name'])\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId : No missing values\n",
      "Pclass : No missing values\n",
      "Name : No missing values\n",
      "Sex : No missing values\n",
      "SibSp : No missing values\n",
      "Parch : No missing values\n",
      "Ticket : No missing values\n",
      "Fare : No missing values\n"
     ]
    }
   ],
   "source": [
    "df = titanic_df.copy()\n",
    "test_json, df = data_cleaning_suggestions(df, 'Survived')\n",
    "with open('suggestions.json', \"w\") as outfile:\n",
    "        outfile.write(json.dumps(test_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
       "0         0       3    0  22.0      1      0   7.2500           0           0   \n",
       "1         1       1    1  38.0      1      0  71.2833           1           0   \n",
       "2         1       3    1  26.0      0      0   7.9250           0           0   \n",
       "3         1       1    1  35.0      1      0  53.1000           0           0   \n",
       "4         0       3    0  35.0      0      0   8.0500           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 1682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns(df, ['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "convert_ordinal_category(df, 'Sex', [0, 1])\n",
    "df = convert_nominal_categories(df, ['Embarked'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass False (891, 11) OUTLIER\n",
      "Pclass False (891, 11)\n",
      "Pclass : No missing values\n",
      "Pclass False (891, 11)\n",
      "Sex False (891, 10) OUTLIER\n",
      "Sex False (891, 10)\n",
      "Sex : No missing values\n",
      "Sex False (891, 10)\n",
      "Age False (891, 10) OUTLIER\n",
      "Age False (889, 10)\n",
      "Age False (889, 10)\n",
      "SibSp False (889, 10) OUTLIER\n",
      "SibSp False (859, 10)\n",
      "SibSp : No missing values\n",
      "SibSp False (859, 10)\n",
      "Parch False (859, 10) OUTLIER\n",
      "Parch False (844, 10)\n",
      "Parch : No missing values\n",
      "Parch False (844, 10)\n",
      "Fare False (844, 9) OUTLIER\n",
      "Fare False (825, 9)\n",
      "Fare : No missing values\n",
      "Fare False (825, 9)\n",
      "Embarked False (825, 8) OUTLIER\n",
      "Embarked False (825, 8)\n",
      "Embarked False (825, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
       "0         0       3    0  22.0      1      0   7.2500           0           0   \n",
       "1         1       1    1  38.0      1      0  71.2833           1           0   \n",
       "2         1       3    1  26.0      0      0   7.9250           0           0   \n",
       "3         1       1    1  35.0      1      0  53.1000           0           0   \n",
       "4         0       3    0  35.0      0      0   8.0500           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 1978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = json.load(open('suggestions.json'))\n",
    "test_df = titanic_df.copy()\n",
    "test_df = clean_data(test_df, 'Survived', operations)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 12)\n",
      "(825, 10)\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(test_df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 1686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.compare(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by=['Age'], inplace=True)\n",
    "# test_df.sort_values(by=['Age'], inplace=True)\n",
    "df.to_csv('suggestions.csv', index=False)\n",
    "test_df.to_csv('test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 1983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(test_df.loc[:, test_df.columns != 'Survived'], test_df['Survived'], test_size=0.2)\n",
    "\n",
    "clf = SVC(kernel='linear', random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1984,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       104\n",
      "           1       0.78      0.70      0.74        61\n",
      "\n",
      "    accuracy                           0.82       165\n",
      "   macro avg       0.81      0.79      0.80       165\n",
      "weighted avg       0.82      0.82      0.82       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' A1', ' A3', ' Q2', ' Q3', ' A5', ' Q5', ' A4', ' A6', nan,\n",
       "       ' A1.', ' A5.'], dtype=object)"
      ]
     },
     "execution_count": 1966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = read_data('../data/raw/cars/cars.csv', header=0)\n",
    "cars.head()\n",
    "cars['model'].unique()\n",
    "# cars['model'] = cars['model'].str.strip()\n",
    "# cars['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1967,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID : No missing values\n",
      "year : No missing values\n",
      "transmission : No missing values\n",
      "fuelType : No missing values\n",
      "tax : No missing values\n",
      "mpg : No missing values\n",
      "engineSize : No missing values\n",
      "ownerName : No missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2019    2242\n",
       "2016    1417\n",
       "2017    1403\n",
       "2015     697\n",
       "2018     574\n",
       "2020     449\n",
       "2014     300\n",
       "2013     207\n",
       "2012      57\n",
       "2011      29\n",
       "2010      20\n",
       "2009      15\n",
       "2008      13\n",
       "2007       6\n",
       "2006       4\n",
       "2005       4\n",
       "2004       1\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 1967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cars.copy()\n",
    "test_json, df = data_cleaning_suggestions(cars, 'price')\n",
    "with open('suggestions.json', \"w\") as outfile:\n",
    "        outfile.write(json.dumps(test_json))\n",
    "cars['year'].value_counts()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model False (7438, 11) OUTLIER\n",
      "model False (7438, 11)\n",
      "model False (7438, 11)\n",
      "year False (7438, 11) OUTLIER\n",
      "year False (7375, 11)\n",
      "year : No missing values\n",
      "year False (7375, 11)\n",
      "transmission False (7375, 11) OUTLIER\n",
      "transmission False (7375, 11)\n",
      "transmission : No missing values\n",
      "transmission False "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar_\\AppData\\Local\\Temp\\ipykernel_8836\\1929179420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].astype(datatype)\n",
      "C:\\Users\\omar_\\AppData\\Local\\Temp\\ipykernel_8836\\2367574136.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].str.strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7375, 13)\n",
      "mileage False (7375, 13) OUTLIER\n",
      "mileage False (7277, 13)\n",
      "mileage False (7277, 13)\n",
      "fuelType False (7277, 13) OUTLIER\n",
      "fuelType False (7277, 13)\n",
      "fuelType : No missing values\n",
      "fuelType False (7277, 15)\n",
      "tax False (7277, 15) OUTLIER\n",
      "tax False (7269, 15)\n",
      "tax : No missing values\n",
      "tax False (7269, 15)\n",
      "mpg False (7269, 15) OUTLIER\n",
      "mpg False (7233, 15)\n",
      "mpg : No missing values\n",
      "mpg False (7233, 15)\n",
      "engineSize False (7233, 15) OUTLIER\n",
      "engineSize False (7233, 15)\n",
      "engineSize : No missing values\n",
      "engineSize False (7233, 15)\n",
      "state False (7233, 15) OUTLIER\n",
      "state False (7233, 15)\n",
      "state False (7233, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>transmission_Automatic</th>\n",
       "      <th>transmission_Manual</th>\n",
       "      <th>transmission_Semi-Auto</th>\n",
       "      <th>fuelType_Diesel</th>\n",
       "      <th>fuelType_Hybrid</th>\n",
       "      <th>fuelType_Petrol</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10999</td>\n",
       "      <td>19865.0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>18400</td>\n",
       "      <td>27672.0</td>\n",
       "      <td>125</td>\n",
       "      <td>49.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>15945</td>\n",
       "      <td>27306.0</td>\n",
       "      <td>125</td>\n",
       "      <td>61.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>8490</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>20</td>\n",
       "      <td>68.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>17297</td>\n",
       "      <td>31433.0</td>\n",
       "      <td>145</td>\n",
       "      <td>64.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  year  price  mileage  tax   mpg  engineSize  transmission_Automatic  \\\n",
       "0      0  2016  10999  19865.0    0  76.3           3                       0   \n",
       "1      1  2017  18400  27672.0  125  49.6           5                       0   \n",
       "2      1  2016  15945  27306.0  125  61.4           5                       0   \n",
       "3      1  2015   8490  40000.0   20  68.9           5                       0   \n",
       "4      5  2018  17297  31433.0  145  64.2           3                       0   \n",
       "\n",
       "   transmission_Manual  transmission_Semi-Auto  fuelType_Diesel  \\\n",
       "0                    1                       0                1   \n",
       "1                    1                       0                0   \n",
       "2                    0                       1                1   \n",
       "3                    1                       0                1   \n",
       "4                    1                       0                1   \n",
       "\n",
       "   fuelType_Hybrid  fuelType_Petrol  state_New  state_Used  \n",
       "0                0                0          0           1  \n",
       "1                0                1          0           1  \n",
       "2                0                0          0           1  \n",
       "3                0                0          0           1  \n",
       "4                0                0          0           1  "
      ]
     },
     "execution_count": 1968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = json.load(open('suggestions.json'))\n",
    "test_df = cars.copy()\n",
    "test_df = clean_data(test_df, 'price', operations)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7233, 15)"
      ]
     },
     "execution_count": 1969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1972,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    test_df.loc[:, test_df.columns != 'price'], test_df[\"price\"], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF error:  0.008168815686525662\n",
      "RF error:  0.09038150079814819\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(\"RF error: \", mean_squared_log_error(y_test, y_pred, squared=True))\n",
    "print(\"RF error: \", mean_squared_log_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b5f24a5c162335a5bbbbd167f52c9e84eea168404a8cc68c92525facb849ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
