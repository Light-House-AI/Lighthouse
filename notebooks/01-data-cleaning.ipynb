{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name, header=0, sep=','):\n",
    "    \"\"\"\n",
    "    Reads a csv file and returns a pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_name, sep=sep, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_float(value):\n",
    "    \"\"\"\n",
    "    Try to parse a string as a float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_correct_datatype(df, column):\n",
    "    float_count = df[column].apply(lambda x: try_parse_float(x)).sum() - df[column].isna().sum()\n",
    "    percentage_float = ((df.shape[0] - float_count) / df.shape[0]) * 100\n",
    "    if percentage_float <= 25:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(val, type):\n",
    "    \"\"\"\n",
    "    Convert a value to a given type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type == 'int64':\n",
    "            return np.int64(val)\n",
    "        elif type == 'float64':\n",
    "            return np.float64(val)\n",
    "        elif type == 'uint8':\n",
    "            return np.uint8(val)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric_or_categorical(df, column):\n",
    "    unique_values = df[column].unique()\n",
    "    if ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100 < 93:\n",
    "        return True, ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100\n",
    "    return False, ((df.shape[0] - len(unique_values)) / df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Removes columns from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows(df, rows):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop(rows, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_condition(df, conition):\n",
    "    return df[~conition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Removes duplicates from a dataframe\n",
    "    \"\"\"\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datatype(df, column, datatype):\n",
    "    \"\"\"\n",
    "    Converts a column to a datatype\n",
    "    \"\"\"\n",
    "    if datatype == 'object':\n",
    "        df[column] = df[column].astype(datatype)\n",
    "    else:\n",
    "        df[column] = df[column].apply(lambda x: convert_type(x, datatype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_numeric(df, column, min=-np.inf, max=np.inf):\n",
    "    \"\"\"\n",
    "    Removes rows from a dataframe based on a condition\n",
    "    \"\"\"\n",
    "    if min != -np.inf and max != np.inf:\n",
    "        return df[(df[column] >= min) & (df[column] <= max)]\n",
    "    elif min == -np.inf and max != np.inf:\n",
    "        return df[(df[column] <= max)]\n",
    "    elif min != -np.inf and max == np.inf:\n",
    "        return df[(df[column] >= min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_std(df, column, std=3):\n",
    "    \"\"\"\n",
    "    Detect outliers based on standard deviation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set upper and lower limit to 3 standard deviation\n",
    "    random_data_std = np.std(df[column])\n",
    "    random_data_mean = np.mean(df[column])\n",
    "    anomaly_cut_off = random_data_std * std\n",
    "    \n",
    "    lower_limit  = random_data_mean - anomaly_cut_off \n",
    "    upper_limit = random_data_mean + anomaly_cut_off\n",
    "\n",
    "    # Generate outliers\n",
    "    outliers = (df[column] < lower_limit) | (df[column] > upper_limit)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_isolation_forest(df, column, contamination=0.1):\n",
    "    \"\"\"\n",
    "    Detect outliers based on isolation forest\n",
    "    \"\"\"\n",
    "    # Create isolation forest\n",
    "    clf = IsolationForest(random_state=0, contamination=contamination)\n",
    "    predictions = clf.fit_predict(df[column].to_numpy().reshape(-1, 1))   \n",
    "    return predictions == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_category_levenshtein(df, column, correct_categories, threshold=80):\n",
    "    \"\"\"\n",
    "    Corrects a column by using fuzzywuzzy to find the correct category\n",
    "    \"\"\"\n",
    "    inconsistent_categories = pd.array(list(set(df[column].unique()) - set(correct_categories)))\n",
    "    \n",
    "    for inconsistent_category in inconsistent_categories:\n",
    "        potential_match = process.extractOne(inconsistent_category, correct_categories)\n",
    "        if potential_match[1] > threshold:\n",
    "            df.loc[df[column] == inconsistent_category, column] = potential_match[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nominal_categories(df, columns):\n",
    "    \"\"\"\n",
    "    Converts categorical data to numeric data\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ordinal_category(df, column, order):\n",
    "    df[column].replace(to_replace=df[column].unique(), value=order, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, column, value):\n",
    "    \"\"\"\n",
    "    Fills missing values in a column with a value\n",
    "    \"\"\"\n",
    "    df[column].fillna(value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df, column):\n",
    "    \"\"\"\n",
    "    Drops missing values in a column\n",
    "    \"\"\"\n",
    "    df.dropna(subset=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_average_mode(df, column, is_numeric):\n",
    "    \"\"\"\n",
    "    Fills missing values in a column with the average or mode\n",
    "    \"\"\"\n",
    "    if not is_numeric:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(df, column, is_numeric):\n",
    "    \"\"\"\n",
    "    Imputation using KNN\n",
    "    \"\"\"\n",
    "    x_train = df[~df[column].isna()].copy()\n",
    "    x_train.dropna(inplace=True)\n",
    "    \n",
    "    y_train = x_train[column]\n",
    "    x_train = x_train[x_train.columns[x_train.columns != column]]\n",
    "    x_train = x_train[x_train.columns[x_train.dtypes != 'object']]\n",
    "     \n",
    "        \n",
    "    x_predict = df[df[column].isna()][df.columns[df.columns != column]].copy()\n",
    "    x_predict = x_predict[x_predict.columns[x_predict.dtypes != 'object']]\n",
    "    \n",
    "    if x_predict.shape[0] == 0:\n",
    "        return\n",
    "    \n",
    "    if is_numeric:\n",
    "        # REGRESSION\n",
    "        knn_regressor = KNeighborsRegressor()\n",
    "        knn_regressor.fit(x_train, y_train)\n",
    "        y_predict = knn_regressor.predict(x_predict)\n",
    "        df.loc[df[column].isna(), column] = y_predict\n",
    "    else:\n",
    "        # CLASSIFICATION\n",
    "        knn_classifier = KNeighborsClassifier()\n",
    "        knn_classifier.fit(x_train, y_train)\n",
    "        y_predict = knn_classifier.predict(x_predict)\n",
    "        df.loc[df[column].isna(), column] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_data_filler(df, column, output_column, is_numeric, no_corr=0.01, low_corr=0.5):\n",
    "    # if df[column].isna().sum() == 0:\n",
    "    #     print(column, \"No missing values\")\n",
    "    #     return\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    drop_missing_values(df_temp, column)\n",
    "    if df_temp[column].dtype == 'object':\n",
    "        convert_ordinal_category(df_temp, column, [x for x in range(len(df_temp[column].unique()))])\n",
    "        \n",
    "    p_score = df_temp[column].corr(df_temp[output_column], method='pearson')\n",
    "    \n",
    "    if p_score >= -no_corr and p_score <= no_corr:\n",
    "        # NO CORRELATION\n",
    "        if ((df.shape[0] - df[column].isna().sum()) / df.shape[0]) * 100 >= 50:\n",
    "            # MISSING VALUES ARE TOO LARGE\n",
    "            # print(column, p_score, \"No correlation, missing values too large\")\n",
    "            remove_columns(df, [column])\n",
    "            return 'column'\n",
    "        else:\n",
    "            # MISSING VALUES ARE SMALL\n",
    "            # print(column, p_score, \"No correlation, missing values small\")\n",
    "            drop_missing_values(df, column)\n",
    "            return 'row'\n",
    "    elif (p_score >= -low_corr and p_score < -no_corr) or (p_score > no_corr and p_score <= low_corr):\n",
    "        # LOW CORRELATION\n",
    "        # print(column, p_score, \"Low correlation\")\n",
    "        fill_average_mode(df, column, is_numeric)\n",
    "        return 'average'\n",
    "    elif p_score >= -1 and p_score <= 1:\n",
    "        # HIGH CORRELATION\n",
    "        # print(column, p_score, \"High correlation\")\n",
    "        knn_impute(df, column, is_numeric)\n",
    "        return 'knn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_suggestions(df, output_column):\n",
    "    df_jsons = []\n",
    "    for col in df.columns[df.columns != output_column]:\n",
    "        col_json = {}\n",
    "        col_json.update({\"column_name\": col})\n",
    "        \n",
    "        # Detect Datatype\n",
    "        detect_correct_datatype(df, col)\n",
    "        if df[col].dtype == 'object':\n",
    "            col_json.update({\"datatype\": \"object\"})\n",
    "        elif df[col].dtype == 'int64':\n",
    "            col_json.update({\"datatype\": \"int64\"})\n",
    "        elif df[col].dtype == 'float64':\n",
    "            col_json.update({\"datatype\": \"float64\"})\n",
    "        elif df[col].dtype == 'uint8':\n",
    "            col_json.update({'datatype': 'uint8'})\n",
    "        \n",
    "        # Detect Numeric or Categorical\n",
    "        is_numeric = False\n",
    "        if df[col].dtype != 'object':\n",
    "            is_numeric, _ = is_numeric_or_categorical(df, col)\n",
    "        col_json.update({'is_numeric': is_numeric})\n",
    "        \n",
    "        print(col, df[col].dtype, is_numeric)\n",
    "        # Detect Outliers\n",
    "        if is_numeric:\n",
    "            outliers = detect_outliers_std(df, col)\n",
    "            drop_rows_condition(df, outliers)\n",
    "        elif df[col].dtype != 'object':\n",
    "            outliers = detect_outliers_isolation_forest(df, col)\n",
    "            drop_rows_condition(df, outliers)\n",
    "        elif df[col].dtype == 'object':\n",
    "            df_temp = df.copy()\n",
    "            convert_ordinal_category(df_temp, col, [x for x in range(len(df_temp[col].unique()))])\n",
    "            outliers = detect_outliers_isolation_forest(df_temp, col)\n",
    "            try:\n",
    "                correct_category_levenshtein(df, col, df[~outliers].unique())\n",
    "            except:\n",
    "                df.loc[outliers, col] = np.nan\n",
    "            \n",
    "        if is_numeric:\n",
    "            col_json.update({'min': df[col].min(), 'max': df[col].max(), 'mean': df[col].mean()})\n",
    "            col_json.update({'unique_count': np.nan, 'unique_values': np.nan})\n",
    "        else:\n",
    "            col_json.update({'min': np.nan, 'max': np.nan, 'mean': np.nan})\n",
    "            col_json.update({'unique_count': len(df[col].unique()), 'unique_values': df[col].unique().tolist()})\n",
    "            \n",
    "        # Missing Data Filler\n",
    "        method = automatic_data_filler(df, col, output_column, is_numeric)\n",
    "        col_json.update({\"dropped\": True if method == 'column' else False})\n",
    "        col_json.update({'fill_method': \"automatic\"})\n",
    "        \n",
    "        if method != 'column':\n",
    "            if is_numeric:\n",
    "                col_json.update({'min': df[col].min(), 'max': df[col].max(), 'mean': df[col].mean()})\n",
    "                col_json.update({'unique_count': np.nan, 'unique_values': np.nan})\n",
    "            else:\n",
    "                col_json.update({'min': np.nan, 'max': np.nan, 'mean': np.nan})\n",
    "                col_json.update({'unique_count': len(df[col].unique()), 'unique_values': df[col].unique().tolist()})\n",
    "            \n",
    "        # completing json\n",
    "        col_json.update({'is_nominal': np.nan})\n",
    "        col_json.update({'ordinal_order': []})\n",
    "                \n",
    "        df_jsons.append(col_json)\n",
    "            \n",
    "    return df_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, output_column, operations):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic_df = read_data('../data/raw/titanic/titanic.csv', header=0)\n",
    "print(titanic_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_suggestions(titanic_df, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_columns(titanic_df, ['Cabin'])\n",
    "# drop_missing_values(titanic_df, 'Embarked')\n",
    "# knn_impute(titanic_df, 'Age', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare    Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  B96 B98        S  \n",
       "1      0          PC 17599  71.2833      C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  B96 B98        S  \n",
       "3      0            113803  53.1000     C123        S  \n",
       "4      0            373450   8.0500  B96 B98        S  "
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(titanic_df.dtypes)\n",
    "print(titanic_df.isna().sum())\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId No missing values\n",
      "Pclass No missing values\n",
      "Name No missing values\n",
      "Sex No missing values\n",
      "Age -0.07722109457217764 Low correlation\n",
      "SibSp No missing values\n",
      "Parch No missing values\n",
      "Ticket No missing values\n",
      "Fare No missing values\n",
      "Cabin 0.04578929038654076 Low correlation\n",
      "Embarked 0.10866867101787406 Low correlation\n"
     ]
    }
   ],
   "source": [
    "automatic_data_filler(titanic_df, 'PassengerId', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'Pclass', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Name', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Sex', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Age', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'SibSp', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'Parch', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Ticket', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Fare', 'Survived', True)\n",
    "automatic_data_filler(titanic_df, 'Cabin', 'Survived', False)\n",
    "automatic_data_filler(titanic_df, 'Embarked', 'Survived', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris  female  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare    Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  B96 B98        S  \n",
       "1      0          PC 17599  71.2833      C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  B96 B98        S  \n",
       "3      0            113803  53.1000     C123        S  \n",
       "4      0            373450   8.0500  B96 B98        S  "
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId -0.005006660767066487\n",
      "Pclass -0.3384810359610147\n",
      "Name -0.005006660767066487\n",
      "Sex 0.5433513806577551\n",
      "Age -0.07722109457217764\n",
      "SibSp -0.017358360479534228\n",
      "Parch 0.09331700774224289\n",
      "Ticket -0.003852775513776319\n",
      "Fare 0.26818861687447865\n",
      "Cabin 0.08604457970131162\n",
      "Embarked -0.10891351318273423\n"
     ]
    }
   ],
   "source": [
    "# df_temp = titanic_df.copy()\n",
    "# for col in titanic_df.columns[titanic_df.columns != 'Survived']:\n",
    "#     drop_missing_values(df_temp, col)\n",
    "#     if df_temp[col].dtype == 'object':\n",
    "#         convert_ordinal_category(df_temp, col, [x for x in range(len(df_temp[col].unique()))])\n",
    "#     print(col, df_temp[col].corr(df_temp['Survived'], method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Pclass, dtype: float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\University\\GP\\AutoML\\notebooks\\01-data-cleaning.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/University/GP/AutoML/notebooks/01-data-cleaning.ipynb#ch0000065?line=0'>1</a>\u001b[0m detect_outliers_isolation_forest(titanic_df, \u001b[39m'\u001b[39;49m\u001b[39mPclass\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32md:\\University\\GP\\AutoML\\notebooks\\01-data-cleaning.ipynb Cell 13'\u001b[0m in \u001b[0;36mdetect_outliers_isolation_forest\u001b[1;34m(df, column, contamination)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University/GP/AutoML/notebooks/01-data-cleaning.ipynb#ch0000009?line=9'>10</a>\u001b[0m df\u001b[39m.\u001b[39mloc[df[column][predictions \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], column] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University/GP/AutoML/notebooks/01-data-cleaning.ipynb#ch0000009?line=10'>11</a>\u001b[0m unique_values \u001b[39m=\u001b[39m df[column][predictions \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/University/GP/AutoML/notebooks/01-data-cleaning.ipynb#ch0000009?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m outliers \u001b[39m!=\u001b[39;49m []:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University/GP/AutoML/notebooks/01-data-cleaning.ipynb#ch0000009?line=12'>13</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University/GP/AutoML/notebooks/01-data-cleaning.ipynb#ch0000009?line=13'>14</a>\u001b[0m         outliers \u001b[39m=\u001b[39m correct_category_levenshtein(outliers, column, unique_values)\n",
      "File \u001b[1;32mc:\\Users\\omar_\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/omar_/anaconda3/lib/site-packages/pandas/core/generic.py?line=1524'>1525</a>\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/omar_/anaconda3/lib/site-packages/pandas/core/generic.py?line=1525'>1526</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/omar_/anaconda3/lib/site-packages/pandas/core/generic.py?line=1526'>1527</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/omar_/anaconda3/lib/site-packages/pandas/core/generic.py?line=1527'>1528</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/omar_/anaconda3/lib/site-packages/pandas/core/generic.py?line=1528'>1529</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/omar_/anaconda3/lib/site-packages/pandas/core/generic.py?line=1529'>1530</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "detect_outliers_isolation_forest(titanic_df, 'Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25b5f24a5c162335a5bbbbd167f52c9e84eea168404a8cc68c92525facb849ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
